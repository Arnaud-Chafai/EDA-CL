{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDIy003pvcWf"
      },
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aldomunaretto/immune_deep_learning/blob/main/notebooks/01_intro_DL/05_keras_imbalanced_classification.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PcNY5jmmYx5"
      },
      "source": [
        "# Artificial Neural Networks - Imbalanced classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP_IuFT-amjg"
      },
      "source": [
        "## Credit Card Fraud Detection\n",
        "\n",
        "Reference: https://keras.io/examples/structured_data/imbalanced_classification/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Mp3amP1mYx7"
      },
      "source": [
        "### Introduction\n",
        "\n",
        "This example looks at the\n",
        "[Kaggle Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud/)\n",
        "dataset to demonstrate how\n",
        "to train a classification model on data with highly imbalanced classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ai8fPwcamjh"
      },
      "source": [
        "### Download Dataset from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "DyaXFmYxamjh"
      },
      "outputs": [],
      "source": [
        "# # Install Kaggle library\n",
        "# !pip install kaggle\n",
        "\n",
        "# # Download and unzip the dataset\n",
        "# !kaggle datasets download -d mlg-ulb/creditcardfraud -p /content/drive/MyDrive/data\n",
        "# !unzip /content/drive/MyDrive/data/creditcardfraud.zip -d /content/drive/MyDrive/data\n",
        "\n",
        "# print(\"Dataset downloaded and unzipped\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx-CI60Ramji"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "3ZgHien-amji"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "# Import the proper libraries for keras\n",
        "import keras\n",
        "from tensorflow.keras import regularizers, Sequential\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.metrics import TruePositives, Precision, Recall, AUC\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fobCaf4JmYx9"
      },
      "source": [
        "### Vectorize the CSV data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "js9oJAp3amjj",
        "outputId": "c68f8362-dc3d-431d-8079-762e508e73be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HEADER: \"Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount\",\"Class\"\n",
            "EXAMPLE FEATURES: [0.0, -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705, -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62]\n",
            "features.shape: (284807, 30)\n",
            "targets.shape: (284807, 1)\n"
          ]
        }
      ],
      "source": [
        "# Reading the CSV file\n",
        "fname = \"/content/drive/MyDrive/data/creditcard.csv\"\n",
        "\n",
        "all_features = []\n",
        "all_targets = []\n",
        "with open(fname) as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i == 0:\n",
        "            print(\"HEADER:\", line.strip())\n",
        "            continue  # Skip header\n",
        "        fields = line.strip().split(\",\")\n",
        "        all_features.append([float(v.replace('\"', \"\")) for v in fields[:-1]])\n",
        "        all_targets.append([int(fields[-1].replace('\"', \"\"))])\n",
        "        if i == 1:\n",
        "            print(\"EXAMPLE FEATURES:\", all_features[-1])\n",
        "\n",
        "features = np.array(all_features, dtype=\"float32\")\n",
        "targets = np.array(all_targets, dtype=\"uint8\")\n",
        "print(\"features.shape:\", features.shape)\n",
        "print(\"targets.shape:\", targets.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(fname)\n",
        "df.info()"
      ],
      "metadata": {
        "id": "7Rw5ANR1cx3F",
        "outputId": "c7a6c0d4-9be7-4c97-efa0-04c805005518",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 284807 entries, 0 to 284806\n",
            "Data columns (total 31 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   Time    284807 non-null  float64\n",
            " 1   V1      284807 non-null  float64\n",
            " 2   V2      284807 non-null  float64\n",
            " 3   V3      284807 non-null  float64\n",
            " 4   V4      284807 non-null  float64\n",
            " 5   V5      284807 non-null  float64\n",
            " 6   V6      284807 non-null  float64\n",
            " 7   V7      284807 non-null  float64\n",
            " 8   V8      284807 non-null  float64\n",
            " 9   V9      284807 non-null  float64\n",
            " 10  V10     284807 non-null  float64\n",
            " 11  V11     284807 non-null  float64\n",
            " 12  V12     284807 non-null  float64\n",
            " 13  V13     284807 non-null  float64\n",
            " 14  V14     284807 non-null  float64\n",
            " 15  V15     284807 non-null  float64\n",
            " 16  V16     284807 non-null  float64\n",
            " 17  V17     284807 non-null  float64\n",
            " 18  V18     284807 non-null  float64\n",
            " 19  V19     284807 non-null  float64\n",
            " 20  V20     284807 non-null  float64\n",
            " 21  V21     284807 non-null  float64\n",
            " 22  V22     284807 non-null  float64\n",
            " 23  V23     284807 non-null  float64\n",
            " 24  V24     284807 non-null  float64\n",
            " 25  V25     284807 non-null  float64\n",
            " 26  V26     284807 non-null  float64\n",
            " 27  V27     284807 non-null  float64\n",
            " 28  V28     284807 non-null  float64\n",
            " 29  Amount  284807 non-null  float64\n",
            " 30  Class   284807 non-null  int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 67.4 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "PQfmfs2rdNYa",
        "outputId": "498b0aa1-18f8-4cd6-a8cb-3c40679f0059",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Time            V1            V2            V3            V4  \\\n",
              "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
              "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
              "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
              "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
              "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
              "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
              "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
              "\n",
              "                 V5            V6            V7            V8            V9  \\\n",
              "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
              "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
              "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
              "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
              "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
              "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
              "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
              "\n",
              "       ...           V21           V22           V23           V24  \\\n",
              "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
              "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
              "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
              "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
              "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
              "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
              "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
              "\n",
              "                V25           V26           V27           V28         Amount  \\\n",
              "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
              "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
              "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
              "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
              "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
              "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
              "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
              "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
              "\n",
              "               Class  \n",
              "count  284807.000000  \n",
              "mean        0.001727  \n",
              "std         0.041527  \n",
              "min         0.000000  \n",
              "25%         0.000000  \n",
              "50%         0.000000  \n",
              "75%         0.000000  \n",
              "max         1.000000  \n",
              "\n",
              "[8 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-113f00ed-6a6e-4c04-9030-db75b95dbda9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>284807.000000</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>284807.000000</td>\n",
              "      <td>284807.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>94813.859575</td>\n",
              "      <td>1.168375e-15</td>\n",
              "      <td>3.416908e-16</td>\n",
              "      <td>-1.379537e-15</td>\n",
              "      <td>2.074095e-15</td>\n",
              "      <td>9.604066e-16</td>\n",
              "      <td>1.487313e-15</td>\n",
              "      <td>-5.556467e-16</td>\n",
              "      <td>1.213481e-16</td>\n",
              "      <td>-2.406331e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>1.654067e-16</td>\n",
              "      <td>-3.568593e-16</td>\n",
              "      <td>2.578648e-16</td>\n",
              "      <td>4.473266e-15</td>\n",
              "      <td>5.340915e-16</td>\n",
              "      <td>1.683437e-15</td>\n",
              "      <td>-3.660091e-16</td>\n",
              "      <td>-1.227390e-16</td>\n",
              "      <td>88.349619</td>\n",
              "      <td>0.001727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>47488.145955</td>\n",
              "      <td>1.958696e+00</td>\n",
              "      <td>1.651309e+00</td>\n",
              "      <td>1.516255e+00</td>\n",
              "      <td>1.415869e+00</td>\n",
              "      <td>1.380247e+00</td>\n",
              "      <td>1.332271e+00</td>\n",
              "      <td>1.237094e+00</td>\n",
              "      <td>1.194353e+00</td>\n",
              "      <td>1.098632e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>7.345240e-01</td>\n",
              "      <td>7.257016e-01</td>\n",
              "      <td>6.244603e-01</td>\n",
              "      <td>6.056471e-01</td>\n",
              "      <td>5.212781e-01</td>\n",
              "      <td>4.822270e-01</td>\n",
              "      <td>4.036325e-01</td>\n",
              "      <td>3.300833e-01</td>\n",
              "      <td>250.120109</td>\n",
              "      <td>0.041527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.640751e+01</td>\n",
              "      <td>-7.271573e+01</td>\n",
              "      <td>-4.832559e+01</td>\n",
              "      <td>-5.683171e+00</td>\n",
              "      <td>-1.137433e+02</td>\n",
              "      <td>-2.616051e+01</td>\n",
              "      <td>-4.355724e+01</td>\n",
              "      <td>-7.321672e+01</td>\n",
              "      <td>-1.343407e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.483038e+01</td>\n",
              "      <td>-1.093314e+01</td>\n",
              "      <td>-4.480774e+01</td>\n",
              "      <td>-2.836627e+00</td>\n",
              "      <td>-1.029540e+01</td>\n",
              "      <td>-2.604551e+00</td>\n",
              "      <td>-2.256568e+01</td>\n",
              "      <td>-1.543008e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>54201.500000</td>\n",
              "      <td>-9.203734e-01</td>\n",
              "      <td>-5.985499e-01</td>\n",
              "      <td>-8.903648e-01</td>\n",
              "      <td>-8.486401e-01</td>\n",
              "      <td>-6.915971e-01</td>\n",
              "      <td>-7.682956e-01</td>\n",
              "      <td>-5.540759e-01</td>\n",
              "      <td>-2.086297e-01</td>\n",
              "      <td>-6.430976e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.283949e-01</td>\n",
              "      <td>-5.423504e-01</td>\n",
              "      <td>-1.618463e-01</td>\n",
              "      <td>-3.545861e-01</td>\n",
              "      <td>-3.171451e-01</td>\n",
              "      <td>-3.269839e-01</td>\n",
              "      <td>-7.083953e-02</td>\n",
              "      <td>-5.295979e-02</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>84692.000000</td>\n",
              "      <td>1.810880e-02</td>\n",
              "      <td>6.548556e-02</td>\n",
              "      <td>1.798463e-01</td>\n",
              "      <td>-1.984653e-02</td>\n",
              "      <td>-5.433583e-02</td>\n",
              "      <td>-2.741871e-01</td>\n",
              "      <td>4.010308e-02</td>\n",
              "      <td>2.235804e-02</td>\n",
              "      <td>-5.142873e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.945017e-02</td>\n",
              "      <td>6.781943e-03</td>\n",
              "      <td>-1.119293e-02</td>\n",
              "      <td>4.097606e-02</td>\n",
              "      <td>1.659350e-02</td>\n",
              "      <td>-5.213911e-02</td>\n",
              "      <td>1.342146e-03</td>\n",
              "      <td>1.124383e-02</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>139320.500000</td>\n",
              "      <td>1.315642e+00</td>\n",
              "      <td>8.037239e-01</td>\n",
              "      <td>1.027196e+00</td>\n",
              "      <td>7.433413e-01</td>\n",
              "      <td>6.119264e-01</td>\n",
              "      <td>3.985649e-01</td>\n",
              "      <td>5.704361e-01</td>\n",
              "      <td>3.273459e-01</td>\n",
              "      <td>5.971390e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.863772e-01</td>\n",
              "      <td>5.285536e-01</td>\n",
              "      <td>1.476421e-01</td>\n",
              "      <td>4.395266e-01</td>\n",
              "      <td>3.507156e-01</td>\n",
              "      <td>2.409522e-01</td>\n",
              "      <td>9.104512e-02</td>\n",
              "      <td>7.827995e-02</td>\n",
              "      <td>77.165000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>172792.000000</td>\n",
              "      <td>2.454930e+00</td>\n",
              "      <td>2.205773e+01</td>\n",
              "      <td>9.382558e+00</td>\n",
              "      <td>1.687534e+01</td>\n",
              "      <td>3.480167e+01</td>\n",
              "      <td>7.330163e+01</td>\n",
              "      <td>1.205895e+02</td>\n",
              "      <td>2.000721e+01</td>\n",
              "      <td>1.559499e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>2.720284e+01</td>\n",
              "      <td>1.050309e+01</td>\n",
              "      <td>2.252841e+01</td>\n",
              "      <td>4.584549e+00</td>\n",
              "      <td>7.519589e+00</td>\n",
              "      <td>3.517346e+00</td>\n",
              "      <td>3.161220e+01</td>\n",
              "      <td>3.384781e+01</td>\n",
              "      <td>25691.160000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-113f00ed-6a6e-4c04-9030-db75b95dbda9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-113f00ed-6a6e-4c04-9030-db75b95dbda9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-113f00ed-6a6e-4c04-9030-db75b95dbda9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-14747e8b-d867-4fe3-9619-fa8da890c046\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-14747e8b-d867-4fe3-9619-fa8da890c046')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-14747e8b-d867-4fe3-9619-fa8da890c046 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54Jn5yBCmYx_"
      },
      "source": [
        "### Prepare a validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3vaUw0ymYx_",
        "outputId": "bbf663ea-ae10-4394-a992-400e4ac571ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 227846\n",
            "Number of validation samples: 56961\n"
          ]
        }
      ],
      "source": [
        "num_val_samples = int(len(features) * 0.2)\n",
        "X_train = features[:-num_val_samples]\n",
        "y_train = targets[:-num_val_samples]\n",
        "X_test = features[-num_val_samples:]\n",
        "y_test = targets[-num_val_samples:]\n",
        "\n",
        "print(\"Number of training samples:\", len(X_train))\n",
        "print(\"Number of validation samples:\", len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features"
      ],
      "metadata": {
        "id": "U6h_d5lBcEbb",
        "outputId": "61b1fa72-3775-4a44-fd82-6103c662e82b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.0000000e+00, -1.3598071e+00, -7.2781175e-02, ...,\n",
              "         1.3355838e-01, -2.1053053e-02,  1.4962000e+02],\n",
              "       [ 0.0000000e+00,  1.1918571e+00,  2.6615071e-01, ...,\n",
              "        -8.9830989e-03,  1.4724169e-02,  2.6900001e+00],\n",
              "       [ 1.0000000e+00, -1.3583541e+00, -1.3401631e+00, ...,\n",
              "        -5.5352796e-02, -5.9751842e-02,  3.7866000e+02],\n",
              "       ...,\n",
              "       [ 1.7278800e+05,  1.9195650e+00, -3.0125386e-01, ...,\n",
              "         4.4547720e-03, -2.6560828e-02,  6.7879997e+01],\n",
              "       [ 1.7278800e+05, -2.4044006e-01,  5.3048253e-01, ...,\n",
              "         1.0882074e-01,  1.0453282e-01,  1.0000000e+01],\n",
              "       [ 1.7279200e+05, -5.3341252e-01, -1.8973334e-01, ...,\n",
              "        -2.4153087e-03,  1.3648914e-02,  2.1700000e+02]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Cd1crUpmYyC"
      },
      "source": [
        "### Normalización + semilla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {
        "id": "cuv0jyuDmYyD",
        "outputId": "0b9bf98f-c005-4a56-f782-26c466512297",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_features mu, sigma [ 9.72985254e-06 -4.99238553e-08 -1.49481309e-07  4.70997929e-06\n",
            "  1.04751805e-07 -3.37099550e-07  2.59797616e-07  6.72313483e-10\n",
            " -1.43351585e-07  1.13865312e-07  5.24606918e-08 -1.09009591e-06\n",
            "  6.24808081e-07 -1.95501570e-07 -1.01077042e-07  2.27438157e-08\n",
            "  2.55664858e-08 -3.92054773e-07  1.16144641e-07 -9.48189580e-08\n",
            "  3.63741208e-07  2.80278584e-07  8.40823517e-08 -7.57773151e-08\n",
            " -1.55235682e-07  6.83880671e-07  1.08841531e-08 -3.03192600e-08\n",
            "  1.14463985e-08 -8.06893695e-07] [0.99998254 0.9999752  0.99995184 0.9999744  0.99998105 0.9999654\n",
            " 0.99997044 0.9999639  0.99991703 0.9999617  0.9999607  0.99996996\n",
            " 0.99996406 0.99997354 0.9999689  0.99997693 0.99997944 0.9999634\n",
            " 0.99997306 0.9999727  0.99993575 0.9999414  0.99998456 0.9999309\n",
            " 0.9999576  0.9999833  0.9999894  0.9999168  0.99992394 0.99987143]\n",
            "test_features mu, sigma [ 1.9960041   0.17281522  0.04075707 -0.6122728  -0.15515524  0.2320748\n",
            " -0.11553436  0.10928366 -0.0164728  -0.00990407  0.00779863 -0.36899468\n",
            "  0.21308044 -0.0819493  -0.17018075 -0.26296836  0.03108337 -0.08667558\n",
            "  0.13568324  0.04443581 -0.06383979  0.04445167  0.16164926  0.07861558\n",
            " -0.00912813 -0.3747331  -0.02917251 -0.00286129 -0.02935679 -0.0494036 ] [0.19323882 1.0269796  0.9791416  0.9353758  1.0066239  1.0045216\n",
            " 1.0352798  1.0309207  0.93513215 0.88413745 0.9765406  0.8763461\n",
            " 0.66440904 0.87120724 0.95042855 0.8645983  0.94545966 0.8449431\n",
            " 0.9647607  0.96215844 0.9450572  0.93033284 1.1057464  0.94819283\n",
            " 0.9972045  1.0756283  0.9528022  1.0390149  0.9375045  0.99132943]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed = 42\n",
        "random.seed(seed)          # Semilla para el generador aleatorio de Python\n",
        "np.random.seed(seed)       # Semilla para NumPy\n",
        "tf.random.set_seed(seed)   # Semilla para TensorFlow\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_norm = scaler.fit_transform(X_train)\n",
        "X_test_norm = scaler.transform(X_test)\n",
        "\n",
        "print('train_features mu, sigma', X_train_norm.mean(0), X_train_norm.std(0))\n",
        "print('test_features mu, sigma', X_test_norm.mean(0), X_test_norm.std(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nED2hxvmYyD"
      },
      "source": [
        "### Build a binary classification model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_norm.shape)"
      ],
      "metadata": {
        "id": "-fsvAOcmgqXo",
        "outputId": "81253c8d-424c-4c05-f63a-4c8b66acf3c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(227846, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {
        "id": "k-l5Sp7umYyE",
        "outputId": "47e7cf15-4f08-4c8a-80ed-63c1dedb6dc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_35\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_35\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ hidden_layer_1 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m1,984\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_54 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden_layer_2 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_55 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden_layer_3 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_56 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden_layer_4 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_57 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Output_layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ hidden_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,984</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ hidden_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,529\u001b[0m (56.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,529</span> (56.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,529\u001b[0m (56.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,529</span> (56.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tensorflow.keras import regularizers\n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "#Input_layer\n",
        "model.add(Input(shape=(30,), name = \"Input_layer\"))\n",
        "\n",
        "#Hidden_layer\n",
        "model.add(Dense(64, activation= \"relu\",\n",
        "                kernel_regularizer = regularizers.l2(0.001),name = \"hidden_layer_1\"))\n",
        "model.add(layers.Dropout(0.3))\n",
        "\n",
        "model.add(Dense(64, activation= \"relu\",\n",
        "                kernel_regularizer = regularizers.l2(0.001), name = \"hidden_layer_2\"))\n",
        "model.add(layers.Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Dense(64, activation= \"relu\",\n",
        "                kernel_regularizer = regularizers.l2(0.001), name = \"hidden_layer_3\"))\n",
        "model.add(layers.Dropout(0.1))\n",
        "\n",
        "model.add(Dense(64, activation= \"relu\",\n",
        "                kernel_regularizer = regularizers.l2(0.001), name = \"hidden_layer_4\"))\n",
        "model.add(layers.Dropout(0.1))\n",
        "\n",
        "#Output_layer\n",
        "model.add(Dense(1, activation = \"sigmoid\", name = \"Output_layer\"))\n",
        "\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaCr4ISpmYyF"
      },
      "source": [
        "### Practice: detects 90% of frauds in test dataset (TP >= 68)\n",
        "\n",
        "**Tips**: check the following documentation (class weight parameter): https://keras.io/api/models/model_training_apis/#fit-method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {
        "id": "KFNCP9bSmYyG"
      },
      "outputs": [],
      "source": [
        "# Definir las métricas\n",
        "metrics = [\n",
        "  keras.metrics.TruePositives(name=\"tp\"),\n",
        "  keras.metrics.FalsePositives(name=\"fp\"),\n",
        "  keras.metrics.AUC(name=\"auc\")\n",
        "]\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(\n",
        "    optimizer = Adam(learning_rate=0.001),\n",
        "    loss = \"binary_crossentropy\",\n",
        "    metrics = metrics,\n",
        ")\n",
        "\n",
        "\n",
        "# Definir los callbacks\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=20,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Balanceo de clases"
      ],
      "metadata": {
        "id": "yrv7qXjptSH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Clacular los pesos de clase\n",
        "from sklearn.utils import class_weight\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train.flatten()\n",
        ")\n",
        "\n",
        "#Convertir a diccionario\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "class_weights"
      ],
      "metadata": {
        "id": "HI_Ctqy6tQOs",
        "outputId": "6edb1861-9002-4b00-9061-0334f753a729",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.500916769629203, 1: 273.1966426858513}"
            ]
          },
          "metadata": {},
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento\n",
        "model.fit(\n",
        "    X_train_norm,\n",
        "    y_train,\n",
        "    batch_size=1000,\n",
        "    epochs=100,\n",
        "    callbacks= callbacks,\n",
        "    verbose=1,\n",
        "    validation_split=0.20,\n",
        "    class_weight=class_weights,\n",
        "    shuffle =True\n",
        ")"
      ],
      "metadata": {
        "id": "xBWtg7XynmPK",
        "outputId": "b7a1e7ca-c7f9-40ef-99ce-28f19e679e94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - auc: 0.7441 - fp: 21077.5156 - loss: 0.8644 - tp: 141.9402 - val_auc: 0.9286 - val_fp: 1432.0000 - val_loss: 0.4180 - val_tp: 45.0000\n",
            "Epoch 2/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - auc: 0.9781 - fp: 3118.9619 - loss: 0.3850 - tp: 166.7120 - val_auc: 0.9509 - val_fp: 1608.0000 - val_loss: 0.3368 - val_tp: 45.0000\n",
            "Epoch 3/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9805 - fp: 3149.3586 - loss: 0.3441 - tp: 169.0489 - val_auc: 0.9498 - val_fp: 3514.0000 - val_loss: 0.4316 - val_tp: 47.0000\n",
            "Epoch 4/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9855 - fp: 4120.4839 - loss: 0.3359 - tp: 169.9946 - val_auc: 0.9500 - val_fp: 1267.0000 - val_loss: 0.2720 - val_tp: 46.0000\n",
            "Epoch 5/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9890 - fp: 3101.4836 - loss: 0.2958 - tp: 172.5544 - val_auc: 0.9509 - val_fp: 1389.0000 - val_loss: 0.2586 - val_tp: 46.0000\n",
            "Epoch 6/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9873 - fp: 3009.9294 - loss: 0.2862 - tp: 172.3098 - val_auc: 0.9517 - val_fp: 1074.0000 - val_loss: 0.2283 - val_tp: 45.0000\n",
            "Epoch 7/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9912 - fp: 2678.6848 - loss: 0.2531 - tp: 175.6848 - val_auc: 0.9490 - val_fp: 1099.0000 - val_loss: 0.2199 - val_tp: 46.0000\n",
            "Epoch 8/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9941 - fp: 2969.2119 - loss: 0.2399 - tp: 175.1141 - val_auc: 0.9504 - val_fp: 1202.0000 - val_loss: 0.2052 - val_tp: 46.0000\n",
            "Epoch 9/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9933 - fp: 2840.6140 - loss: 0.2353 - tp: 173.9674 - val_auc: 0.9539 - val_fp: 922.0000 - val_loss: 0.1842 - val_tp: 45.0000\n",
            "Epoch 10/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9956 - fp: 2831.5381 - loss: 0.2127 - tp: 177.3478 - val_auc: 0.9493 - val_fp: 790.0000 - val_loss: 0.1688 - val_tp: 45.0000\n",
            "Epoch 11/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9959 - fp: 2630.2988 - loss: 0.2005 - tp: 177.5870 - val_auc: 0.9493 - val_fp: 801.0000 - val_loss: 0.1614 - val_tp: 45.0000\n",
            "Epoch 12/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9927 - fp: 3045.3696 - loss: 0.2153 - tp: 176.3750 - val_auc: 0.9497 - val_fp: 1349.0000 - val_loss: 0.1753 - val_tp: 47.0000\n",
            "Epoch 13/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.9951 - fp: 3185.0598 - loss: 0.1953 - tp: 176.8424 - val_auc: 0.9493 - val_fp: 1504.0000 - val_loss: 0.1793 - val_tp: 47.0000\n",
            "Epoch 14/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.9910 - fp: 5487.9023 - loss: 0.2232 - tp: 175.9837 - val_auc: 0.9537 - val_fp: 1235.0000 - val_loss: 0.1629 - val_tp: 46.0000\n",
            "Epoch 15/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.9963 - fp: 2972.7229 - loss: 0.1839 - tp: 176.2989 - val_auc: 0.9507 - val_fp: 992.0000 - val_loss: 0.1453 - val_tp: 46.0000\n",
            "Epoch 16/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9972 - fp: 2681.5488 - loss: 0.1699 - tp: 177.8913 - val_auc: 0.9525 - val_fp: 1160.0000 - val_loss: 0.1476 - val_tp: 46.0000\n",
            "Epoch 17/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9972 - fp: 2887.6140 - loss: 0.1645 - tp: 177.1848 - val_auc: 0.9496 - val_fp: 845.0000 - val_loss: 0.1290 - val_tp: 45.0000\n",
            "Epoch 18/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9970 - fp: 3018.6250 - loss: 0.1638 - tp: 177.6413 - val_auc: 0.9508 - val_fp: 912.0000 - val_loss: 0.1269 - val_tp: 46.0000\n",
            "Epoch 19/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9975 - fp: 2849.0544 - loss: 0.1511 - tp: 178.3424 - val_auc: 0.9523 - val_fp: 685.0000 - val_loss: 0.1129 - val_tp: 46.0000\n",
            "Epoch 20/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9980 - fp: 2676.7554 - loss: 0.1387 - tp: 179.2500 - val_auc: 0.9531 - val_fp: 635.0000 - val_loss: 0.1110 - val_tp: 44.0000\n",
            "Epoch 21/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9979 - fp: 2843.9565 - loss: 0.1367 - tp: 179.8152 - val_auc: 0.9529 - val_fp: 884.0000 - val_loss: 0.1160 - val_tp: 46.0000\n",
            "Epoch 22/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9977 - fp: 3394.3640 - loss: 0.1396 - tp: 180.0054 - val_auc: 0.9524 - val_fp: 1030.0000 - val_loss: 0.1166 - val_tp: 47.0000\n",
            "Epoch 23/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9980 - fp: 3041.9565 - loss: 0.1325 - tp: 179.6304 - val_auc: 0.9550 - val_fp: 463.0000 - val_loss: 0.0941 - val_tp: 44.0000\n",
            "Epoch 24/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9978 - fp: 3132.9402 - loss: 0.1297 - tp: 178.2663 - val_auc: 0.9530 - val_fp: 1029.0000 - val_loss: 0.1101 - val_tp: 46.0000\n",
            "Epoch 25/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9984 - fp: 2544.7500 - loss: 0.1205 - tp: 179.9130 - val_auc: 0.9533 - val_fp: 713.0000 - val_loss: 0.1002 - val_tp: 46.0000\n",
            "Epoch 26/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9986 - fp: 2291.6848 - loss: 0.1148 - tp: 180.6902 - val_auc: 0.9537 - val_fp: 853.0000 - val_loss: 0.1053 - val_tp: 45.0000\n",
            "Epoch 27/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9985 - fp: 2421.7554 - loss: 0.1146 - tp: 180.1087 - val_auc: 0.9541 - val_fp: 781.0000 - val_loss: 0.1029 - val_tp: 45.0000\n",
            "Epoch 28/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9985 - fp: 2152.8206 - loss: 0.1121 - tp: 179.7174 - val_auc: 0.9565 - val_fp: 530.0000 - val_loss: 0.0889 - val_tp: 45.0000\n",
            "Epoch 29/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9985 - fp: 2433.7065 - loss: 0.1063 - tp: 181.0815 - val_auc: 0.9527 - val_fp: 721.0000 - val_loss: 0.0960 - val_tp: 45.0000\n",
            "Epoch 30/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9984 - fp: 2317.6250 - loss: 0.1113 - tp: 180.6087 - val_auc: 0.9496 - val_fp: 1335.0000 - val_loss: 0.1208 - val_tp: 47.0000\n",
            "Epoch 31/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.9980 - fp: 3102.6140 - loss: 0.1188 - tp: 180.0652 - val_auc: 0.9543 - val_fp: 768.0000 - val_loss: 0.0927 - val_tp: 45.0000\n",
            "Epoch 32/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.9986 - fp: 2459.2988 - loss: 0.1044 - tp: 181.2228 - val_auc: 0.9556 - val_fp: 546.0000 - val_loss: 0.0816 - val_tp: 45.0000\n",
            "Epoch 33/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9977 - fp: 2487.9836 - loss: 0.1165 - tp: 179.5870 - val_auc: 0.9472 - val_fp: 470.0000 - val_loss: 0.0773 - val_tp: 45.0000\n",
            "Epoch 34/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9974 - fp: 2421.6794 - loss: 0.1194 - tp: 180.7663 - val_auc: 0.9465 - val_fp: 576.0000 - val_loss: 0.0841 - val_tp: 45.0000\n",
            "Epoch 35/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9988 - fp: 2110.2012 - loss: 0.0966 - tp: 180.0544 - val_auc: 0.9481 - val_fp: 530.0000 - val_loss: 0.0799 - val_tp: 45.0000\n",
            "Epoch 36/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9988 - fp: 2181.2935 - loss: 0.0953 - tp: 180.1685 - val_auc: 0.9483 - val_fp: 312.0000 - val_loss: 0.0675 - val_tp: 44.0000\n",
            "Epoch 37/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9981 - fp: 2931.3750 - loss: 0.1096 - tp: 179.5544 - val_auc: 0.9530 - val_fp: 1194.0000 - val_loss: 0.0995 - val_tp: 46.0000\n",
            "Epoch 38/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9988 - fp: 2440.2554 - loss: 0.0957 - tp: 181.7391 - val_auc: 0.9492 - val_fp: 276.0000 - val_loss: 0.0651 - val_tp: 44.0000\n",
            "Epoch 39/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9992 - fp: 1345.5381 - loss: 0.0791 - tp: 182.5435 - val_auc: 0.9450 - val_fp: 816.0000 - val_loss: 0.0894 - val_tp: 45.0000\n",
            "Epoch 40/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9984 - fp: 2599.3098 - loss: 0.1016 - tp: 180.6576 - val_auc: 0.9453 - val_fp: 874.0000 - val_loss: 0.0851 - val_tp: 45.0000\n",
            "Epoch 41/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9989 - fp: 2073.9131 - loss: 0.0915 - tp: 180.8315 - val_auc: 0.9479 - val_fp: 315.0000 - val_loss: 0.0643 - val_tp: 44.0000\n",
            "Epoch 42/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9990 - fp: 1646.9457 - loss: 0.0838 - tp: 181.3478 - val_auc: 0.9478 - val_fp: 406.0000 - val_loss: 0.0674 - val_tp: 45.0000\n",
            "Epoch 43/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9984 - fp: 1826.3859 - loss: 0.0876 - tp: 180.3641 - val_auc: 0.9462 - val_fp: 492.0000 - val_loss: 0.0698 - val_tp: 45.0000\n",
            "Epoch 44/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9992 - fp: 1457.4674 - loss: 0.0789 - tp: 181.9783 - val_auc: 0.9469 - val_fp: 364.0000 - val_loss: 0.0663 - val_tp: 44.0000\n",
            "Epoch 45/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.9992 - fp: 1632.4728 - loss: 0.0775 - tp: 182.2609 - val_auc: 0.9488 - val_fp: 267.0000 - val_loss: 0.0606 - val_tp: 44.0000\n",
            "Epoch 46/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.9991 - fp: 1630.0055 - loss: 0.0799 - tp: 181.6304 - val_auc: 0.9483 - val_fp: 361.0000 - val_loss: 0.0654 - val_tp: 44.0000\n",
            "Epoch 47/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9991 - fp: 1456.5164 - loss: 0.0783 - tp: 180.9294 - val_auc: 0.9491 - val_fp: 230.0000 - val_loss: 0.0572 - val_tp: 43.0000\n",
            "Epoch 48/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9989 - fp: 1628.8750 - loss: 0.0825 - tp: 180.4674 - val_auc: 0.9475 - val_fp: 514.0000 - val_loss: 0.0711 - val_tp: 44.0000\n",
            "Epoch 49/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9991 - fp: 1683.1576 - loss: 0.0798 - tp: 181.6739 - val_auc: 0.9402 - val_fp: 241.0000 - val_loss: 0.0585 - val_tp: 44.0000\n",
            "Epoch 50/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9988 - fp: 1497.0164 - loss: 0.0836 - tp: 181.1902 - val_auc: 0.9490 - val_fp: 245.0000 - val_loss: 0.0574 - val_tp: 43.0000\n",
            "Epoch 51/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.9991 - fp: 1503.3533 - loss: 0.0733 - tp: 182.0761 - val_auc: 0.9398 - val_fp: 249.0000 - val_loss: 0.0564 - val_tp: 43.0000\n",
            "Epoch 52/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9992 - fp: 1448.0760 - loss: 0.0724 - tp: 181.5489 - val_auc: 0.9483 - val_fp: 447.0000 - val_loss: 0.0640 - val_tp: 43.0000\n",
            "Epoch 53/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9994 - fp: 1356.9457 - loss: 0.0679 - tp: 183.2880 - val_auc: 0.9490 - val_fp: 324.0000 - val_loss: 0.0631 - val_tp: 43.0000\n",
            "Epoch 54/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9994 - fp: 1264.4076 - loss: 0.0686 - tp: 181.8098 - val_auc: 0.9484 - val_fp: 363.0000 - val_loss: 0.0647 - val_tp: 44.0000\n",
            "Epoch 55/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9993 - fp: 1334.1576 - loss: 0.0689 - tp: 182.1685 - val_auc: 0.9388 - val_fp: 267.0000 - val_loss: 0.0577 - val_tp: 42.0000\n",
            "Epoch 56/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.9992 - fp: 1447.5978 - loss: 0.0700 - tp: 181.6413 - val_auc: 0.9399 - val_fp: 255.0000 - val_loss: 0.0557 - val_tp: 43.0000\n",
            "Epoch 57/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9991 - fp: 1435.4619 - loss: 0.0693 - tp: 182.1685 - val_auc: 0.9393 - val_fp: 265.0000 - val_loss: 0.0549 - val_tp: 42.0000\n",
            "Epoch 58/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9994 - fp: 1106.4674 - loss: 0.0625 - tp: 183.0380 - val_auc: 0.9394 - val_fp: 281.0000 - val_loss: 0.0570 - val_tp: 43.0000\n",
            "Epoch 59/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9993 - fp: 1379.9185 - loss: 0.0676 - tp: 182.2554 - val_auc: 0.9392 - val_fp: 383.0000 - val_loss: 0.0620 - val_tp: 43.0000\n",
            "Epoch 60/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.9991 - fp: 1549.5869 - loss: 0.0720 - tp: 181.2717 - val_auc: 0.9297 - val_fp: 287.0000 - val_loss: 0.0551 - val_tp: 42.0000\n",
            "Epoch 61/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.9988 - fp: 2256.7012 - loss: 0.0811 - tp: 181.4728 - val_auc: 0.9404 - val_fp: 261.0000 - val_loss: 0.0539 - val_tp: 43.0000\n",
            "Epoch 62/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9978 - fp: 1354.4293 - loss: 0.0780 - tp: 181.8967 - val_auc: 0.9477 - val_fp: 383.0000 - val_loss: 0.0607 - val_tp: 44.0000\n",
            "Epoch 63/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9992 - fp: 1335.5000 - loss: 0.0669 - tp: 183.2880 - val_auc: 0.9392 - val_fp: 331.0000 - val_loss: 0.0586 - val_tp: 43.0000\n",
            "Epoch 64/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9994 - fp: 1262.4510 - loss: 0.0646 - tp: 181.6794 - val_auc: 0.9380 - val_fp: 409.0000 - val_loss: 0.0629 - val_tp: 43.0000\n",
            "Epoch 65/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9991 - fp: 1645.9457 - loss: 0.0716 - tp: 181.8478 - val_auc: 0.9554 - val_fp: 571.0000 - val_loss: 0.0712 - val_tp: 43.0000\n",
            "Epoch 66/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9991 - fp: 1907.7228 - loss: 0.0751 - tp: 181.8750 - val_auc: 0.9393 - val_fp: 267.0000 - val_loss: 0.0543 - val_tp: 43.0000\n",
            "Epoch 67/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.9994 - fp: 1192.3098 - loss: 0.0625 - tp: 182.4946 - val_auc: 0.9297 - val_fp: 348.0000 - val_loss: 0.0587 - val_tp: 43.0000\n",
            "Epoch 68/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9992 - fp: 1364.7445 - loss: 0.0688 - tp: 182.2989 - val_auc: 0.9209 - val_fp: 270.0000 - val_loss: 0.0547 - val_tp: 43.0000\n",
            "Epoch 69/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9993 - fp: 1221.4076 - loss: 0.0663 - tp: 181.3967 - val_auc: 0.9217 - val_fp: 189.0000 - val_loss: 0.0507 - val_tp: 43.0000\n",
            "Epoch 70/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.9993 - fp: 1108.4836 - loss: 0.0636 - tp: 182.4239 - val_auc: 0.9203 - val_fp: 307.0000 - val_loss: 0.0575 - val_tp: 43.0000\n",
            "Epoch 71/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9991 - fp: 1475.2664 - loss: 0.0698 - tp: 181.6413 - val_auc: 0.9374 - val_fp: 549.0000 - val_loss: 0.0688 - val_tp: 43.0000\n",
            "Epoch 72/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9994 - fp: 1181.7990 - loss: 0.0611 - tp: 182.8641 - val_auc: 0.9113 - val_fp: 273.0000 - val_loss: 0.0541 - val_tp: 42.0000\n",
            "Epoch 73/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9995 - fp: 877.7065 - loss: 0.0558 - tp: 182.4511 - val_auc: 0.9118 - val_fp: 213.0000 - val_loss: 0.0528 - val_tp: 43.0000\n",
            "Epoch 74/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9995 - fp: 782.4348 - loss: 0.0548 - tp: 182.6848 - val_auc: 0.9121 - val_fp: 168.0000 - val_loss: 0.0497 - val_tp: 41.0000\n",
            "Epoch 75/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.9993 - fp: 1230.7772 - loss: 0.0632 - tp: 181.9402 - val_auc: 0.9458 - val_fp: 353.0000 - val_loss: 0.0582 - val_tp: 43.0000\n",
            "Epoch 76/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - auc: 0.9993 - fp: 1352.3805 - loss: 0.0641 - tp: 182.6794 - val_auc: 0.9312 - val_fp: 162.0000 - val_loss: 0.0482 - val_tp: 42.0000\n",
            "Epoch 77/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9995 - fp: 943.5978 - loss: 0.0553 - tp: 183.0706 - val_auc: 0.9307 - val_fp: 226.0000 - val_loss: 0.0511 - val_tp: 43.0000\n",
            "Epoch 78/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9993 - fp: 1087.3478 - loss: 0.0615 - tp: 181.2283 - val_auc: 0.9398 - val_fp: 235.0000 - val_loss: 0.0517 - val_tp: 43.0000\n",
            "Epoch 79/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.9995 - fp: 1106.5109 - loss: 0.0576 - tp: 182.7337 - val_auc: 0.9218 - val_fp: 161.0000 - val_loss: 0.0472 - val_tp: 41.0000\n",
            "Epoch 80/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9994 - fp: 988.7826 - loss: 0.0567 - tp: 181.7391 - val_auc: 0.9216 - val_fp: 183.0000 - val_loss: 0.0482 - val_tp: 42.0000\n",
            "Epoch 81/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9993 - fp: 1132.4728 - loss: 0.0612 - tp: 181.5435 - val_auc: 0.9214 - val_fp: 208.0000 - val_loss: 0.0503 - val_tp: 42.0000\n",
            "Epoch 82/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9995 - fp: 1028.2990 - loss: 0.0560 - tp: 183.1848 - val_auc: 0.9194 - val_fp: 368.0000 - val_loss: 0.0598 - val_tp: 42.0000\n",
            "Epoch 83/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9990 - fp: 1441.4293 - loss: 0.0686 - tp: 182.0544 - val_auc: 0.9200 - val_fp: 256.0000 - val_loss: 0.0514 - val_tp: 42.0000\n",
            "Epoch 84/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9993 - fp: 1365.1793 - loss: 0.0613 - tp: 182.7337 - val_auc: 0.9027 - val_fp: 136.0000 - val_loss: 0.0451 - val_tp: 40.0000\n",
            "Epoch 85/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9995 - fp: 706.2228 - loss: 0.0506 - tp: 183.2880 - val_auc: 0.9029 - val_fp: 109.0000 - val_loss: 0.0441 - val_tp: 39.0000\n",
            "Epoch 86/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9994 - fp: 938.7880 - loss: 0.0560 - tp: 181.4511 - val_auc: 0.9395 - val_fp: 303.0000 - val_loss: 0.0523 - val_tp: 43.0000\n",
            "Epoch 87/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9993 - fp: 1148.6793 - loss: 0.0600 - tp: 181.3859 - val_auc: 0.9399 - val_fp: 228.0000 - val_loss: 0.0503 - val_tp: 43.0000\n",
            "Epoch 88/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - auc: 0.9994 - fp: 1232.3586 - loss: 0.0593 - tp: 182.2663 - val_auc: 0.9402 - val_fp: 190.0000 - val_loss: 0.0457 - val_tp: 42.0000\n",
            "Epoch 89/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9994 - fp: 1079.2336 - loss: 0.0568 - tp: 183.2880 - val_auc: 0.9219 - val_fp: 108.0000 - val_loss: 0.0425 - val_tp: 40.0000\n",
            "Epoch 90/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9957 - fp: 1061.8260 - loss: 0.1059 - tp: 181.0109 - val_auc: 0.9397 - val_fp: 235.0000 - val_loss: 0.0519 - val_tp: 43.0000\n",
            "Epoch 91/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9994 - fp: 1116.4131 - loss: 0.0582 - tp: 182.4239 - val_auc: 0.9312 - val_fp: 152.0000 - val_loss: 0.0455 - val_tp: 42.0000\n",
            "Epoch 92/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9995 - fp: 889.3587 - loss: 0.0541 - tp: 181.9022 - val_auc: 0.9311 - val_fp: 151.0000 - val_loss: 0.0458 - val_tp: 42.0000\n",
            "Epoch 93/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9995 - fp: 954.1413 - loss: 0.0540 - tp: 182.7609 - val_auc: 0.9124 - val_fp: 112.0000 - val_loss: 0.0435 - val_tp: 40.0000\n",
            "Epoch 94/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9995 - fp: 775.4457 - loss: 0.0504 - tp: 182.2880 - val_auc: 0.9121 - val_fp: 152.0000 - val_loss: 0.0460 - val_tp: 42.0000\n",
            "Epoch 95/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9989 - fp: 873.7228 - loss: 0.0550 - tp: 182.9456 - val_auc: 0.9296 - val_fp: 227.0000 - val_loss: 0.0493 - val_tp: 42.0000\n",
            "Epoch 96/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9989 - fp: 1490.0000 - loss: 0.0747 - tp: 180.9185 - val_auc: 0.9286 - val_fp: 274.0000 - val_loss: 0.0519 - val_tp: 43.0000\n",
            "Epoch 97/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9995 - fp: 934.4185 - loss: 0.0531 - tp: 183.2880 - val_auc: 0.9120 - val_fp: 139.0000 - val_loss: 0.0454 - val_tp: 42.0000\n",
            "Epoch 98/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9996 - fp: 785.6141 - loss: 0.0500 - tp: 182.3370 - val_auc: 0.9119 - val_fp: 171.0000 - val_loss: 0.0465 - val_tp: 40.0000\n",
            "Epoch 99/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9994 - fp: 969.9946 - loss: 0.0559 - tp: 181.8967 - val_auc: 0.9120 - val_fp: 121.0000 - val_loss: 0.0433 - val_tp: 40.0000\n",
            "Epoch 100/100\n",
            "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - auc: 0.9996 - fp: 784.8696 - loss: 0.0512 - tp: 182.5163 - val_auc: 0.9028 - val_fp: 107.0000 - val_loss: 0.0416 - val_tp: 42.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ae37aa19480>"
            ]
          },
          "metadata": {},
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "id": "b9FKSB3GqpBb",
        "outputId": "64e7c75a-e2ad-4fdc-a3f6-44339ef01028",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.03885570541024208\n",
            "Test TP: 62.0\n",
            "Test FP: 93.0\n",
            "Test AUC: 0.9326913356781006\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate(X_test_norm, y_test, verbose=0)\n",
        "print('Test Loss: {}'.format(results[0]))\n",
        "print('Test TP: {}'.format(results[1]))\n",
        "print('Test FP: {}'.format(results[2]))\n",
        "print('Test AUC: {}'.format(results[3]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}