{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping de las noticias con impacto de la página oficial de la EIA\n",
    "\n",
    "Este script utiliza `BeautifulSoup` para hacer un scraping de las noticias con impacto desde la página oficial de la **EIA** (Energy Information Administration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_21424\\1799367000.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "\n",
    "# URL de la página\n",
    "url = \"https://www.eia.gov/todayinenergy/index.php?tg=crude%20oil\"\n",
    "\n",
    "# Obtener el contenido HTML de la página\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Extraer los artículos y fechas\n",
    "articulos = []\n",
    "articulos_html = soup.select(\"div.tie-article.tag-view > h2 > a\")  # Selector para los títulos de artículos\n",
    "fechas_html = soup.select(\"div.tie-article.tag-view > span\")  # Selector más general para las fechas\n",
    "\n",
    "# Iterar sobre los elementos capturados\n",
    "for articulo, fecha in zip(articulos_html, fechas_html):\n",
    "    texto = articulo.get_text(strip=True)\n",
    "    fecha_texto = fecha.get_text(strip=True)\n",
    "\n",
    "    # Agregar al resultado\n",
    "    articulos.append({\n",
    "        'fechas': fecha_texto,\n",
    "        'Noticia_EIA': texto\n",
    "    })\n",
    "\n",
    "# Convertir los resultados en un DataFrame\n",
    "df = pd.DataFrame(articulos)\n",
    "\n",
    "#Convertimos la fecha a formato datetime\n",
    "df['fechas_noticia_EIA'] = pd.to_datetime(df['fechas'])\n",
    "df.drop(columns=\"fechas\",inplace=True)\n",
    "\n",
    "# Guardar en CSV\n",
    "df.to_csv('eia_today_in_energy_with_corrected_dates.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
